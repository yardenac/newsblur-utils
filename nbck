#!/usr/bin/python3

import argparse
import configparser
import lib
import http.cookiejar
import json
import os
import re
import urllib.parse
import urllib.request
import ssl
import sys

#### CONFIG ####

config_global = configparser.ConfigParser()
config_global['DEFAULT'] = {
    'username': 'user',
    'password': 'password',
    'url': 'https://newsblur.com/',
    'configfile' : os.environ['HOME'] + '/.config/newsblur/login',
}
config_global.read(config_global['DEFAULT']['configfile'])
config = config_global['DEFAULT']
numw = 3 # max width of number column (0-999 saved feeds...)

#### CONNECT ####

opener = urllib.request.build_opener()

# set up cookies
opener.add_handler(urllib.request.HTTPCookieProcessor(http.cookiejar.CookieJar()))

# set up secure TLS
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
context.verify_mode = ssl.CERT_REQUIRED
context.load_verify_locations(capath="/etc/ssl/certs")
opener.add_handler(urllib.request.HTTPSHandler(context=context))

def nbtry(opener,*args,post=None):
    if post:
        response = json.loads(opener.open(*args,urllib.parse.urlencode(post).encode("utf-8")).read().decode())
    else:
        response = json.loads(opener.open(*args).read().decode())
    if (response['result'] != 'ok'):
        print("connection failed...")
        return(0)
    if ('code' in response and response['code'] != 1):
        for e in response['errors']['__all__']:
                print(e)
        return(0)
    return(response)

# log in
authdata = urllib.parse.urlencode({
	"username" : config["username"],
	"password" : config["password"],
}).encode()

if not nbtry(opener,config['url']+"api/login",authdata):
    print("login failed")
    sys.exit(1)


#### ROUTINES ####

def list_starred():
    maxw = int(lib.getTerminalSize()[0]/2 - numw - 9 - 7)
    feeds = nbtry(opener,config['url']+"reader/feeds")
    for feed in feeds['starred_counts']:
        id = feed['feed_id']
        if str(id) in feeds['feeds']:
            feed_name = 'https://newsblur.com/site/' + str(id) + '/' + lib.urlify(feeds['feeds'][str(id)]['feed_title'])
        else:
            if (str(id) == 'None'): continue
            feed_name = 'https://newsblur.com/site/' + str(id)
        percent = " (" + "{:1.1f}".format(100 * feed['count'] / feeds['starred_count']) + "%) "
        print(str(feed['count']).rjust(numw) + percent + feed_name[0:maxw]);

def feed_archive(id):
    maxw = int(lib.getTerminalSize()[0])
    storynum = 0
    for page in range(1,100,1):
        for story in nbtry(opener,config['url']+"reader/feed/"+str(id)+"?page="+str(page))["stories"]:
            storynum += 1
            out = str(storynum).rjust(4)+" "+str(page).rjust(2)+" "+story["long_parsed_date"].ljust(13)+" " \
                  +story["story_permalink"]+" " \
                  +story["story_title"].replace("\n"," ").splitlines()[0];
            print(out[0:maxw])

delfeeds = [];

def recursive_folder_parse(obj):
    global delfeeds
    for id in obj:
        if isinstance(id, int):
            delfeeds.append(id);
            continue
        if isinstance(id, dict):
            for key in id.keys():
                recursive_folder_parse(id[key])

def mark_folder_read(name):
    global delfeeds
    if not name: return false
    feeds = nbtry(opener,config['url']+"reader/feeds")
    for folder in feeds["folders"]:
        if not isinstance(folder, dict): continue
        if name not in folder: continue
        recursive_folder_parse(folder[name])

    # build request lines
    line_limit = 8190
    requests = []
    for feed in delfeeds:
        if ((len(requests) == 0) or (requests[len(requests)].length > line_limit - 100)):
            requests.append(config['url']+"reader/mark_feed_as_read?");
        requests[len(requests)] += 'feed_id=' + str(id) + '&'
    for requeststring in requests:
        print(requeststring)
#        marking = nbtry(opener,requeststring)

def show_feed(id):
    print("https://newsblur.com/site/"+str(id)+"/")
    #print(nbtry(opener,config['url']+"rss_feeds/statistics/"+str(id)))
    for story in nbtry(opener,config['url']+"reader/feed/"+str(id)+"?include_story_content=false")["stories"]:
        print("   "+story['short_parsed_date']+"  "+story['story_title'])

def add_feed(url,folder=''):
    if not url: return
    if folder:
        result = nbtry(opener,config['url']+"reader/add_url",post={"folder": folder,"url": url})
    else:
        result = nbtry(opener,config['url']+"reader/add_url",post={"url": url})
    if result["feed"]["id"]:
        show_feed(result["feed"]["id"])

parser = argparse.ArgumentParser()
parser.add_argument('--list_starred', action='store_true', help='List feeds sorted by how many starred')
parser.add_argument('--addfeed', help='Add a feed')
parser.add_argument('--folder', help='Folder to add it to')
args = parser.parse_args()

#### DO STUFF ####

if args.list_starred:
    list_starred();
elif args.addfeed:
    if not args.folder: args.folder = ''
    add_feed(args.addfeed, args.folder)
else:
    print('no options given')

#mark_folder_read('goldpan');
# starred_count
# authenticated
# starred_counts
# user_profile
# categories
# social_feeds
# folders
# result
# social_services
# feeds
# social_profile

#### CLEANUP ####

if not nbtry(opener,config['url']+"api/logout"):
    print("logout failed")
    sys.exit(1)
